{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gpxpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpxpy\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the path to the GPX file\n",
    "gpx_file_path = '/content/Standard_Chartered_Hanoi_Marathon.gpx'\n",
    "\n",
    "# Check if the file exists\n",
    "if not os.path.exists(gpx_file_path):\n",
    "    print(f\"Error: GPX file not found at {gpx_file_path}\")\n",
    "else:\n",
    "    try:\n",
    "        # Open and parse the GPX file\n",
    "        with open(gpx_file_path, 'r') as gpx_file:\n",
    "            gpx = gpxpy.parse(gpx_file)\n",
    "\n",
    "        # Prepare a list to store track points\n",
    "        track_points = []\n",
    "\n",
    "        # Iterate through tracks, segments, and points\n",
    "        for track in gpx.tracks:\n",
    "            for segment in track.segments:\n",
    "                for point in segment.points:\n",
    "                    track_points.append({\n",
    "                        'latitude': point.latitude,\n",
    "                        'longitude': point.longitude,\n",
    "                        'elevation': point.elevation,\n",
    "                        'timestamp': point.time\n",
    "                    })\n",
    "\n",
    "        # Create a pandas DataFrame from the extracted track points\n",
    "        df_gpx = pd.DataFrame(track_points)\n",
    "\n",
    "        # Print the total number of points\n",
    "        print(f\"{len(df_gpx)} points\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing the GPX file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic\n",
    "import numpy as np\n",
    "\n",
    "# 1. Convert the 'timestamp' column to datetime objects\n",
    "df_gpx['timestamp'] = pd.to_datetime(df_gpx['timestamp'])\n",
    "\n",
    "# 2. Calculate the time difference in seconds between consecutive points\n",
    "df_gpx['time_diff_seconds'] = df_gpx['timestamp'].diff().dt.total_seconds()\n",
    "\n",
    "# 3. and 4. Calculate the Haversine distance in kilometers between consecutive points\n",
    "# Using geopy's geodesic which is more accurate for long distances than Haversine\n",
    "# It's also readily available and accounts for the Earth's ellipsoid shape.\n",
    "# Using apply with lambda for row-wise calculation, it's efficient enough for this dataset size.\n",
    "\n",
    "def calculate_geodesic_distance(row):\n",
    "    if pd.isna(row['latitude_prev']) or pd.isna(row['longitude_prev']):\n",
    "        return np.nan\n",
    "    point1 = (row['latitude_prev'], row['longitude_prev'])\n",
    "    point2 = (row['latitude'], row['longitude'])\n",
    "    return geodesic(point1, point2).km\n",
    "\n",
    "# Create shifted columns for previous latitude and longitude to calculate differences\n",
    "df_gpx['latitude_prev'] = df_gpx['latitude'].shift(1)\n",
    "df_gpx['longitude_prev'] = df_gpx['longitude'].shift(1)\n",
    "\n",
    "df_gpx['distance_km'] = df_gpx.apply(calculate_geodesic_distance, axis=1)\n",
    "\n",
    "# Drop the temporary shifted columns\n",
    "df_gpx.drop(columns=['latitude_prev', 'longitude_prev'], inplace=True)\n",
    "\n",
    "# 5. Calculate the pace in seconds per kilometer\n",
    "# Handle division by zero or where distance is very small (near zero) by setting pace to NaN or 0\n",
    "df_gpx['pace_sec_per_km'] = df_gpx.apply(lambda row:\n",
    "    row['time_diff_seconds'] / row['distance_km'] if row['distance_km'] > 0 else np.nan,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# 6. Convert 'pace_sec_per_km' to minutes per kilometer\n",
    "df_gpx['pace_min_per_km'] = df_gpx['pace_sec_per_km'] / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Initial number of points: {len(df_gpx)}\")\n",
    "\n",
    "# 1. Calculate Q1 and Q3 for 'pace_min_per_km', excluding NaN values\n",
    "Q1_pace = df_gpx['pace_min_per_km'].quantile(0.25)\n",
    "Q3_pace = df_gpx['pace_min_per_km'].quantile(0.75)\n",
    "\n",
    "# 2. Calculate the Interquartile Range (IQR) for pace\n",
    "IQR_pace = Q3_pace - Q1_pace\n",
    "\n",
    "# 3. Define the lower and upper bounds for pace outlier detection\n",
    "lower_bound_pace = Q1_pace - 1.5 * IQR_pace\n",
    "upper_bound_pace = Q3_pace + 1.5 * IQR_pace\n",
    "\n",
    "print(f\"\\n--- Pace Outlier Bounds ---\")\n",
    "print(f\"Q1 (Pace): {Q1_pace:.2f} min/km\")\n",
    "print(f\"Q3 (Pace): {Q3_pace:.2f} min/km\")\n",
    "print(f\"IQR (Pace): {IQR_pace:.2f} min/km\")\n",
    "print(f\"Lower bound for pace: {lower_bound_pace:.2f} min/km\")\n",
    "print(f\"Upper bound for pace: {upper_bound_pace:.2f} min/km\")\n",
    "\n",
    "# Calculate Q1 and Q3 for 'distance_km', excluding NaN values\n",
    "Q1_dist = df_gpx['distance_km'].quantile(0.25)\n",
    "Q3_dist = df_gpx['distance_km'].quantile(0.75)\n",
    "\n",
    "# Calculate the Interquartile Range (IQR) for distance\n",
    "IQR_dist = Q3_dist - Q1_dist\n",
    "\n",
    "# Define the lower and upper bounds for distance outlier detection\n",
    "lower_bound_dist = Q1_dist - 1.5 * IQR_dist\n",
    "upper_bound_dist = Q3_dist + 1.5 * IQR_dist\n",
    "\n",
    "print(f\"\\n--- Distance Outlier Bounds ---\")\n",
    "print(f\"Q1 (Distance): {Q1_dist:.2e} km\")\n",
    "print(f\"Q3 (Distance): {Q3_dist:.2e} km\")\n",
    "print(f\"IQR (Distance): {IQR_dist:.2e} km\")\n",
    "print(f\"Lower bound for distance: {lower_bound_dist:.2e} km\")\n",
    "print(f\"Upper bound for distance: {upper_bound_dist:.2e} km\")\n",
    "\n",
    "# 4. Create a new DataFrame by filtering out outliers and NaN values for both pace and distance\n",
    "df_gpx_cleaned = df_gpx[\n",
    "    (df_gpx['pace_min_per_km'] >= lower_bound_pace) &\n",
    "    (df_gpx['pace_min_per_km'] <= upper_bound_pace) &\n",
    "    (df_gpx['distance_km'] >= lower_bound_dist) &\n",
    "    (df_gpx['distance_km'] <= upper_bound_dist)\n",
    "].dropna(subset=['pace_min_per_km', 'distance_km']).copy()\n",
    "\n",
    "# 5. Print the number of points removed and the number of remaining points\n",
    "points_removed = len(df_gpx) - len(df_gpx_cleaned)\n",
    "print(f\"\\nNumber of points removed as outliers or NaNs: {points_removed}\")\n",
    "print(f\"Number of remaining points after outlier removal: {len(df_gpx_cleaned)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 2. Define the target maximum real-world error as 10 meters and the average Earth radius\n",
    "target_error_meters = 10  # meters\n",
    "earth_radius_meters = 6371000 # average Earth radius in meters\n",
    "\n",
    "# 3. Calculate the angular distance in radians\n",
    "# This approximates the distance at the equator. For more accuracy at a specific latitude,\n",
    "# the radius of curvature at that latitude could be used, but for simplicity and given\n",
    "# the small error, average radius is sufficient for this context.\n",
    "angular_distance_radians = target_error_meters / earth_radius_meters\n",
    "\n",
    "# 4. Convert this angular distance from radians to degrees to obtain the rdp_epsilon_degrees\n",
    "optimal_rdp_epsilon = np.degrees(angular_distance_radians)\n",
    "\n",
    "# 6. Print the calculated RDP epsilon (tolerance) in degrees\n",
    "print(f\"Target Maximum Real-World Error: {target_error_meters} meters\")\n",
    "print(f\"Calculated Optimal RDP Epsilon (tolerance): {optimal_rdp_epsilon:.6f} degrees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rdp import rdp\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Prepare the data for RDP: a NumPy array of [latitude, longitude] pairs\n",
    "points_for_rdp = df_gpx_cleaned[['latitude', 'longitude']].values\n",
    "\n",
    "# 2. Apply the RDP algorithm to get the simplified points (latitude, longitude pairs)\n",
    "simplified_points_coords = rdp(points_for_rdp, algo=\"iter\", epsilon=optimal_rdp_epsilon)\n",
    "\n",
    "# Convert the simplified coordinates array to a set of tuples for efficient lookup\n",
    "simplified_set = set(map(tuple, simplified_points_coords))\n",
    "\n",
    "# Find the indices in the original df_gpx_cleaned that correspond to the simplified points\n",
    "simplified_points_indices = []\n",
    "for i, (lat, lon) in enumerate(points_for_rdp):\n",
    "    if (lat, lon) in simplified_set:\n",
    "        simplified_points_indices.append(i)\n",
    "\n",
    "# 3. Create the simplified DataFrame by selecting points using the found indices\n",
    "df_simplified_10m_error = df_gpx_cleaned.iloc[simplified_points_indices].copy()\n",
    "\n",
    "# 4. Reset index for a clean DataFrame\n",
    "df_simplified_10m_error.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"RDP algorithm applied. Simplified track stored in df_simplified_10m_error.\")\n",
    "print(f\"Number of points in df_gpx_cleaned: {len(df_gpx_cleaned)}\")\n",
    "print(f\"Number of points in df_simplified_10m_error: {len(df_simplified_10m_error)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install matplotlib geopandas contextily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2fd1d031"
   },
   "source": [
    "Now, I will convert the `df_simplified_10m_error` DataFrame into a GeoDataFrame, which is required for plotting with `geopandas` and `contextily`. I'll create `Point` geometries from the latitude and longitude columns and set the appropriate Coordinate Reference System (CRS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as cx\n",
    "\n",
    "# Create a GeoDataFrame from df_simplified_10m_error\n",
    "geometry = [Point(xy) for xy in zip(df_simplified_10m_error['longitude'], df_simplified_10m_error['latitude'])]\n",
    "gdf_simplified = geopandas.GeoDataFrame(df_simplified_10m_error, geometry=geometry)\n",
    "\n",
    "# Set the Coordinate Reference System (CRS) to WGS84 (latitude/longitude)\n",
    "gdf_simplified = gdf_simplified.set_crs('EPSG:4326')\n",
    "\n",
    "# Reproject to Web Mercator (EPSG:3857) for compatibility with contextily basemaps\n",
    "gdf_simplified_webmercator = gdf_simplified.to_crs(epsg=3857)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Plot the simplified points\n",
    "gdf_simplified_webmercator.plot(ax=ax, color='red', markersize=10, alpha=0.7)\n",
    "\n",
    "# Add OpenStreetMap basemap\n",
    "cx.add_basemap(ax, crs=gdf_simplified_webmercator.crs.to_string(), source=cx.providers.OpenStreetMap.Mapnik)\n",
    "\n",
    "# Remove x and y ticks and their labels\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as cx\n",
    "\n",
    "# Create a LineString from your longitude/latitude columns\n",
    "line = LineString(zip(df_simplified_10m_error['longitude'], df_simplified_10m_error['latitude']))\n",
    "\n",
    "# Create a GeoDataFrame containing the single line\n",
    "gdf_simplified = gpd.GeoDataFrame(index=[0], geometry=[line], crs='EPSG:4326')\n",
    "\n",
    "# Reproject to Web Mercator for compatibility with contextily basemap\n",
    "gdf_simplified_webmercator = gdf_simplified.to_crs(epsg=3857)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Plot the line instead of points\n",
    "gdf_simplified_webmercator.plot(ax=ax, color='black', linewidth=2, alpha=0.8)\n",
    "\n",
    "# Add OpenStreetMap basemap\n",
    "cx.add_basemap(ax, crs=gdf_simplified_webmercator.crs.to_string(), source=cx.providers.OpenStreetMap.Mapnik)\n",
    "\n",
    "# Clean up axes\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simplified_10m_error_renamed = df_simplified_10m_error.rename(\n",
    "    columns={'latitude': 'lat', 'longitude': 'lon'}\n",
    ")\n",
    "\n",
    "df_simplified_10m_error_renamed[['lat', 'lon']].to_csv('simplified_track.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
