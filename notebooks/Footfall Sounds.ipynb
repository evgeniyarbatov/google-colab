{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
      "Requirement already satisfied: soundfile in /usr/local/lib/python3.12/dist-packages (0.13.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile) (2.23)\n"
     ]
    }
   ],
   "source": [
    "pip install numpy soundfile scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-0fe3525a-30f6-42da-87cf-61236054d6e8\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-0fe3525a-30f6-42da-87cf-61236054d6e8\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving vnexpress.gpx to vnexpress.gpx\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "gpx_path = list(uploaded.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing GPX...\n",
      "Loaded 13768 points\n",
      "Source track duration ~ 13767.0s (will be scaled to 60.0s)\n",
      "Average estimated cadence: 220.9 spm\n",
      "Generated 50681 footfall events\n",
      "Writing output to /content/gpx.wav ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "# --- Google Colab Support ---\n",
    "# If running in Google Colab, you can upload a GPX file interactively by running:\n",
    "#\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "# gpx_path = list(uploaded.keys())[0]\n",
    "# !python reconstruct_footfalls.py \"$gpx_path\" output.wav\n",
    "#\n",
    "# Then download output.wav using:\n",
    "# files.download('output.wav')\n",
    "\n",
    "reconstruct_footfalls.py\n",
    "\n",
    "Reconstruct pleasant-sounding footfall audio from a GPX file.\n",
    "\n",
    "Usage:\n",
    "    python reconstruct_footfalls.py input.gpx output.wav\n",
    "\n",
    "What it does (short):\n",
    "- Parses a GPX track (lat, lon, time). If no timestamps present, it linearly maps points across 60s.\n",
    "- Computes ground speed and maps it onto a step rate (cadence) using a simple stride-length model.\n",
    "- Generates footfall events (left/right alternating) with slight randomness and per-step variation.\n",
    "- Synthesizes each footfall as the mix of a short filtered noise \"impact\" and a low-frequency tonal \"body\" with an exponential decay.\n",
    "- Pans left/right and applies mild reverberation (simple Schroeder-style reverb) so the result is pleasant.\n",
    "- Exports a 60-second WAV (float32).\n",
    "\n",
    "Dependencies:\n",
    "    numpy, soundfile, scipy\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from scipy.signal import lfilter, butter\n",
    "\n",
    "SAMPLE_RATE = 44100\n",
    "DURATION = 60.0  # seconds\n",
    "\n",
    "# ---------- utilities ----------\n",
    "\n",
    "def haversine_meters(lat1, lon1, lat2, lon2):\n",
    "    # haversine formula\n",
    "    R = 6371000.0\n",
    "    phi1 = np.radians(lat1)\n",
    "    phi2 = np.radians(lat2)\n",
    "    dphi = np.radians(lat2 - lat1)\n",
    "    dlambda = np.radians(lon2 - lon1)\n",
    "    a = np.sin(dphi / 2.0) ** 2 + np.cos(phi1) * np.cos(phi2) * np.sin(dlambda / 2.0) ** 2\n",
    "    return R * 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "\n",
    "\n",
    "def parse_gpx(gpx_path):\n",
    "    tree = ET.parse(gpx_path)\n",
    "    root = tree.getroot()\n",
    "    # GPX namespace handling\n",
    "    ns = {'default': root.tag[root.tag.find('{')+1:root.tag.find('}')] } if '}' in root.tag else {}\n",
    "\n",
    "    points = []  # list of (lat, lon, time_or_None)\n",
    "    # look for trkpt under trk/trkseg\n",
    "    for trk in root.findall('.//{*}trk'):\n",
    "        for trkseg in trk.findall('.//{*}trkseg'):\n",
    "            for trkpt in trkseg.findall('.//{*}trkpt'):\n",
    "                lat = float(trkpt.attrib.get('lat'))\n",
    "                lon = float(trkpt.attrib.get('lon'))\n",
    "                tnode = trkpt.find('{*}time')\n",
    "                t = None\n",
    "                if tnode is not None and tnode.text:\n",
    "                    try:\n",
    "                        # try parsing ISO8601-ish\n",
    "                        t = datetime.fromisoformat(tnode.text.replace('Z', '+00:00'))\n",
    "                    except Exception:\n",
    "                        try:\n",
    "                            t = datetime.strptime(tnode.text, '%Y-%m-%dT%H:%M:%SZ')\n",
    "                        except Exception:\n",
    "                            t = None\n",
    "                points.append((lat, lon, t))\n",
    "    # fallback: sometimes points are directly under rte/rtept\n",
    "    if not points:\n",
    "        for rtept in root.findall('.//{*}rtept'):\n",
    "            lat = float(rtept.attrib.get('lat'))\n",
    "            lon = float(rtept.attrib.get('lon'))\n",
    "            tnode = rtept.find('{*}time')\n",
    "            t = None\n",
    "            if tnode is not None and tnode.text:\n",
    "                try:\n",
    "                    t = datetime.fromisoformat(tnode.text.replace('Z', '+00:00'))\n",
    "                except Exception:\n",
    "                    t = None\n",
    "            points.append((lat, lon, t))\n",
    "\n",
    "    if not points:\n",
    "        raise ValueError('No track points found in GPX file')\n",
    "    return points\n",
    "\n",
    "\n",
    "# ---------- mapping GPX to timeline ----------\n",
    "\n",
    "def compute_speeds_and_times(points):\n",
    "    # points: list of (lat, lon, datetime or None)\n",
    "    n = len(points)\n",
    "    lats = np.array([p[0] for p in points])\n",
    "    lons = np.array([p[1] for p in points])\n",
    "    times = [p[2] for p in points]\n",
    "\n",
    "    # compute distances between successive points\n",
    "    dists = np.zeros(n)\n",
    "    dt_secs = np.zeros(n)\n",
    "    for i in range(1, n):\n",
    "        dists[i] = haversine_meters(lats[i-1], lons[i-1], lats[i], lons[i])\n",
    "        if times[i] and times[i-1]:\n",
    "            dt = (times[i] - times[i-1]).total_seconds()\n",
    "            dt_secs[i] = max(dt, 1e-3)\n",
    "        else:\n",
    "            dt_secs[i] = 0.0\n",
    "\n",
    "    # if timestamps exist for at least 2 points, create absolute times array\n",
    "    if sum(1 for t in times if t is not None) >= 2:\n",
    "        # create array of seconds since first timestamp\n",
    "        # fill missing timestamps by linear interpolation of point indices\n",
    "        # map provided timestamps to seconds\n",
    "        provided_idx = [i for i, t in enumerate(times) if t is not None]\n",
    "        first_time = times[provided_idx[0]]\n",
    "        sec_times = np.full(n, np.nan)\n",
    "        for i in provided_idx:\n",
    "            sec_times[i] = (times[i] - first_time).total_seconds()\n",
    "        # interpolate gaps\n",
    "        notnan = ~np.isnan(sec_times)\n",
    "        idx = np.arange(n)\n",
    "        sec_times = np.interp(idx, idx[notnan], sec_times[notnan])\n",
    "        # now compute dt_secs from sec_times\n",
    "        dt_secs = np.diff(np.concatenate(([0.0], sec_times)))\n",
    "        dt_secs = np.maximum(dt_secs, 1e-3)\n",
    "        speeds = dists / dt_secs\n",
    "        timeline_seconds = sec_times\n",
    "        source_duration = sec_times[-1]\n",
    "    else:\n",
    "        # no timestamps or only one timestamp -> map points evenly across DURATION\n",
    "        idx = np.arange(n)\n",
    "        timeline_seconds = idx / (n - 1) * DURATION\n",
    "        dt_secs = np.diff(np.concatenate(([0.0], timeline_seconds)))\n",
    "        dt_secs = np.maximum(dt_secs, 1e-3)\n",
    "        speeds = dists / dt_secs\n",
    "        source_duration = min(timeline_seconds[-1], DURATION)\n",
    "\n",
    "    # clamp speeds (avoid infinities)\n",
    "    speeds = np.nan_to_num(speeds, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    return timeline_seconds, speeds, source_duration\n",
    "\n",
    "\n",
    "# ---------- estimate cadence (steps/sec) ----------\n",
    "\n",
    "def estimate_step_rate(speeds_m_s, stride_length_m=0.78):\n",
    "    # Basic model: step_rate = speed / stride_length. stride_length default ~0.78m per step\n",
    "    # Add physiological bounds for walking/running cadence\n",
    "    step_rates = speeds_m_s / stride_length_m\n",
    "    # clamp cadence between 0.5 steps/s (30 spm) and 4 steps/s (240 spm)\n",
    "    step_rates = np.clip(step_rates, 0.4, 4.0)\n",
    "    return step_rates\n",
    "\n",
    "\n",
    "# ---------- generate footfall event times ----------\n",
    "\n",
    "def synthesize_events(timeline_seconds, step_rates):\n",
    "    # timeline_seconds & step_rates are per original GPX point\n",
    "    # We'll resample into denser timeline and produce events by integrating instantaneous rate\n",
    "    total_len = len(timeline_seconds)\n",
    "    # create a fine time grid across source_duration\n",
    "    source_duration = timeline_seconds[-1]\n",
    "    dt = 0.1  # coarse grid for rate integration to create events\n",
    "    grid = np.arange(0.0, source_duration + 1e-8, dt)\n",
    "    # interpolate step rate onto grid\n",
    "    step_rate_grid = np.interp(grid, timeline_seconds, step_rates)\n",
    "\n",
    "    # integrate rate to produce cumulative expected steps\n",
    "    expected_steps = np.cumsum(step_rate_grid * dt)\n",
    "    # produce integer step indices from 0 to floor(last)\n",
    "    n_steps = int(np.floor(expected_steps[-1]))\n",
    "    if n_steps < 2:\n",
    "        # ensure at least two steps for audible result\n",
    "        n_steps = max(2, n_steps)\n",
    "\n",
    "    # find times where expected_steps crosses integers\n",
    "    event_times = []\n",
    "    cur_step = 1\n",
    "    for i in range(1, len(grid)):\n",
    "        while expected_steps[i] >= cur_step and cur_step <= n_steps:\n",
    "            # linear interpolate between grid[i-1] and grid[i]\n",
    "            alpha = ((cur_step - expected_steps[i-1]) / (expected_steps[i] - expected_steps[i-1] + 1e-12))\n",
    "            t = grid[i-1] + alpha * (grid[i] - grid[i-1])\n",
    "            event_times.append(t)\n",
    "            cur_step += 1\n",
    "    event_times = np.array(event_times)\n",
    "\n",
    "    # if nothing found (rare), fill evenly\n",
    "    if len(event_times) == 0:\n",
    "        event_times = np.linspace(0, source_duration, 30)\n",
    "\n",
    "    # add jitter proportional to rate (faster -> less jitter)\n",
    "    # add small per-step variability (normal with sigma 0.02s scaled by rate)\n",
    "    sigma = np.clip(0.04 * (1.0 / (1.0 + np.interp(event_times, timeline_seconds, step_rates))), 0.01, 0.06)\n",
    "    jitter = np.random.normal(scale=sigma)\n",
    "    event_times = event_times + jitter\n",
    "    # keep in bounds\n",
    "    event_times = np.clip(event_times, 0.0, source_duration)\n",
    "\n",
    "    # alternate left/right\n",
    "    sides = np.array(['L' if i % 2 == 0 else 'R' for i in range(len(event_times))])\n",
    "    return event_times, sides\n",
    "\n",
    "\n",
    "# ---------- synthesis building blocks (ASPHALT FOOTSTEPS) ----------\n",
    "\n",
    "# Asphalt footstep model:\n",
    "# - Sharp heel transient (2–6 kHz band)\n",
    "# - Mid-frequency slap (300–900 Hz)\n",
    "# - Low-frequency body thump (70–160 Hz)\n",
    "# - Optional toe-off transient ~40–60 ms after heel strike\n",
    "# - Small randomization for realism\n",
    "\n",
    "import random\n",
    "\n",
    "def make_asphalt_heel(sr=SAMPLE_RATE):\n",
    "    # short, sharp transient\n",
    "    n = int(0.03 * sr)\n",
    "    noise = np.random.randn(n)\n",
    "    b, a = butter(2, [2000/(sr/2), 6000/(sr/2)], btype='band')\n",
    "    heel = lfilter(b, a, noise)\n",
    "    env = exponential_decay_envelope(n, tau_seconds=0.012, sr=sr)\n",
    "    heel = heel * env\n",
    "    heel /= (np.max(np.abs(heel)) + 1e-12)\n",
    "    return heel\n",
    "\n",
    "\n",
    "def make_asphalt_mid(sr=SAMPLE_RATE):\n",
    "    n = int(0.06 * sr)\n",
    "    noise = np.random.randn(n)\n",
    "    b, a = butter(2, [300/(sr/2), 900/(sr/2)], btype='band')\n",
    "    mid = lfilter(b, a, noise)\n",
    "    env = exponential_decay_envelope(n, tau_seconds=0.04, sr=sr)\n",
    "    mid = mid * env\n",
    "    mid /= (np.max(np.abs(mid)) + 1e-12)\n",
    "    return mid\n",
    "\n",
    "\n",
    "def make_asphalt_body(freq=120.0, sr=SAMPLE_RATE):\n",
    "    n = int(0.2 * sr)\n",
    "    t = np.arange(n) / sr\n",
    "    tone = np.sin(2*np.pi*freq*t)\n",
    "    tone += 0.4*np.sin(2*np.pi*(freq*2.1)*t)\n",
    "    env = exponential_decay_envelope(n, tau_seconds=0.09, sr=sr)\n",
    "    tone = tone * env\n",
    "    tone /= (np.max(np.abs(tone)) + 1e-12)\n",
    "    return tone\n",
    "\n",
    "\n",
    "def make_asphalt_toe(sr=SAMPLE_RATE):\n",
    "    n = int(0.02 * sr)\n",
    "    noise = np.random.randn(n)\n",
    "    b, a = butter(2, [2500/(sr/2), 7000/(sr/2)], btype='band')\n",
    "    toe = lfilter(b, a, noise)\n",
    "    env = exponential_decay_envelope(n, tau_seconds=0.008, sr=sr)\n",
    "    toe = toe * env\n",
    "    toe /= (np.max(np.abs(toe)) + 1e-12)\n",
    "    return toe\n",
    "\n",
    "\n",
    "def exponential_decay_envelope(length_samples, tau_seconds, sr=SAMPLE_RATE):\n",
    "    t = np.arange(length_samples) / sr\n",
    "    env = np.exp(-t / tau_seconds)\n",
    "    # normalize to peak 1\n",
    "    env = env / np.max(np.abs(env) + 1e-12)\n",
    "    return env\n",
    "\n",
    "\n",
    "def make_impact(duration_s=0.06, sr=SAMPLE_RATE):\n",
    "    # impact: burst of bandpassed noise (short)\n",
    "    n = int(duration_s * sr)\n",
    "    # white noise\n",
    "    noise = np.random.randn(n)\n",
    "    # highpass then lowpass to make it clicky but not harsh\n",
    "    b, a = butter(2, [300.0 / (sr / 2), 5000.0 / (sr / 2)], btype='band')\n",
    "    impact = lfilter(b, a, noise)\n",
    "    env = exponential_decay_envelope(n, tau_seconds=0.02, sr=sr)\n",
    "    impact = impact * env\n",
    "    # gentle amplitude normalization\n",
    "    impact = impact * 0.8 / (np.max(np.abs(impact)) + 1e-12)\n",
    "    return impact\n",
    "\n",
    "\n",
    "def make_body_tone(duration_s=0.25, freq=150.0, sr=SAMPLE_RATE):\n",
    "    n = int(duration_s * sr)\n",
    "    t = np.arange(n) / sr\n",
    "    tone = np.sin(2 * np.pi * freq * t)\n",
    "    # add slight harmonic\n",
    "    tone += 0.4 * np.sin(2 * np.pi * (freq * 2.0) * t)\n",
    "    env = exponential_decay_envelope(n, tau_seconds=0.08, sr=sr)\n",
    "    tone = tone * env\n",
    "    tone = tone / (np.max(np.abs(tone)) + 1e-12)\n",
    "    return tone\n",
    "\n",
    "\n",
    "def simple_reverb(stereo_signal, sr=SAMPLE_RATE):\n",
    "    # small Schroeder-style reverb: sum of combs + all-pass\n",
    "    # stereo_signal: shape (2, N)\n",
    "    out = stereo_signal.copy()\n",
    "    N = stereo_signal.shape[1]\n",
    "    # comb filters (feedforward delays)\n",
    "    comb_delays = [0.029, 0.037, 0.041]  # seconds\n",
    "    gains = [0.7, 0.65, 0.6]\n",
    "    for d, g in zip(comb_delays, gains):\n",
    "        k = int(d * sr)\n",
    "        if k >= N:\n",
    "            continue\n",
    "        delayed = np.zeros_like(out)\n",
    "        delayed[:, k:] = out[:, :-k] * g\n",
    "        out += delayed\n",
    "    # tiny all-pass\n",
    "    ap_delay = int(0.005 * sr)\n",
    "    if ap_delay < N:\n",
    "        ap = np.zeros_like(out)\n",
    "        ap[:, ap_delay:] = out[:, :-ap_delay] * 0.5\n",
    "        out = out - ap + 0.5 * ap\n",
    "    # mild damping\n",
    "    out *= 0.9\n",
    "    return out\n",
    "\n",
    "\n",
    "# ---------- render ----------\n",
    "\n",
    "def render_audio(event_times, sides, timeline_seconds, source_duration, step_rate_fn_interp, out_duration=DURATION, sr=SAMPLE_RATE):\n",
    "    # Map source_time -> output_time by scaling to out_duration\n",
    "    # No scaling — use absolute times\n",
    "    scale = 1.0\n",
    "    event_times_out = event_times * scale\n",
    "\n",
    "    n_samples = int(out_duration * sr)\n",
    "    stereo = np.zeros((2, n_samples), dtype=np.float32)\n",
    "\n",
    "    # pre-generate base sounds\n",
    "    impact_base = make_impact(duration_s=0.06, sr=sr)\n",
    "    body_base = make_body_tone(duration_s=0.28, freq=120.0, sr=sr)\n",
    "\n",
    "    for i, t in enumerate(event_times_out):\n",
    "        sample_idx = int(t * sr)\n",
    "        if sample_idx >= n_samples:\n",
    "            continue\n",
    "        side = sides[i]\n",
    "        # choose slightly different timbre per foot and per local rate\n",
    "        local_rate = float(step_rate_fn_interp(min(event_times[i], timeline_seconds[-1])))\n",
    "        # map local_rate (steps/s) to tonal brightness\n",
    "        freq = 110.0 + (local_rate - 0.5) * 60.0\n",
    "        body = make_body_tone(duration_s=0.2 + 0.06 * np.random.rand(), freq=freq, sr=sr)\n",
    "        impact = make_impact(duration_s=0.04 + 0.03 * np.random.rand(), sr=sr)\n",
    "\n",
    "        # mix impact + body\n",
    "        snd = np.zeros(max(len(impact), len(body)), dtype=np.float32)\n",
    "        snd[:len(impact)] += impact\n",
    "        snd[:len(body)] += 0.9 * body\n",
    "\n",
    "        # amplitude scaling by local_rate (faster -> slightly louder)\n",
    "        amp = 0.5 + 0.5 * np.tanh((local_rate - 1.0) * 0.8)\n",
    "        snd *= amp * (0.5 + 0.5 * np.random.rand())\n",
    "\n",
    "        # simple stereo pan: L/R or small offset from heading (we alternate)\n",
    "        if side == 'L':\n",
    "            left = snd\n",
    "            right = snd * 0.6\n",
    "        else:\n",
    "            left = snd * 0.6\n",
    "            right = snd\n",
    "\n",
    "        # write into buffer with additive mix\n",
    "        end = sample_idx + len(snd)\n",
    "        if end > n_samples:\n",
    "            end = n_samples\n",
    "            left = left[: end - sample_idx]\n",
    "            right = right[: end - sample_idx]\n",
    "        stereo[0, sample_idx:end] += left\n",
    "        stereo[1, sample_idx:end] += right\n",
    "\n",
    "    # apply simple reverb to make pleasant\n",
    "    stereo = simple_reverb(stereo, sr=sr)\n",
    "\n",
    "    # normalize to avoid clipping\n",
    "    peak = np.max(np.abs(stereo)) + 1e-12\n",
    "    stereo = stereo * (0.95 / peak)\n",
    "    return stereo\n",
    "\n",
    "\n",
    "# ---------- main ----------\n",
    "\n",
    "def main(in_gpx, out_wav):\n",
    "    print('Parsing GPX...')\n",
    "    points = parse_gpx(in_gpx)\n",
    "    print(f'Loaded {len(points)} points')\n",
    "    timeline_seconds, speeds, source_duration = compute_speeds_and_times(points)\n",
    "    print(f'Source track duration ~ {source_duration:.1f}s (will be scaled to {DURATION:.1f}s)')\n",
    "\n",
    "    step_rates = estimate_step_rate(speeds, stride_length_m=0.78)\n",
    "    print(f'Average estimated cadence: {np.mean(step_rates)*60:.1f} spm')\n",
    "\n",
    "    # synthesize events in source time\n",
    "    event_times, sides = synthesize_events(timeline_seconds, step_rates)\n",
    "    print(f'Generated {len(event_times)} footfall events')\n",
    "\n",
    "    # create interp function for local rate mapping (source-time)\n",
    "    def step_rate_fn(t):\n",
    "        return float(np.interp(t, timeline_seconds, step_rates))\n",
    "\n",
    "    stereo = render_audio(event_times, sides, timeline_seconds, source_duration, step_rate_fn, out_duration=DURATION, sr=SAMPLE_RATE)\n",
    "\n",
    "    # write file\n",
    "    print(f'Writing output to {out_wav} ...')\n",
    "    # transpose to shape (N, 2)\n",
    "    out = stereo.T\n",
    "    sf.write(out_wav, out, SAMPLE_RATE, subtype='FLOAT')\n",
    "    print('Done!')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # --- Google Colab friendly entry point ---\n",
    "    # Example usage in Colab:\n",
    "    # from google.colab import files\n",
    "    # uploaded = files.upload()\n",
    "    # gpx_path = list(uploaded.keys())[0]\n",
    "    # in_gpx = gpx_path\n",
    "    # out_wav = '/content/gpx.wav'\n",
    "    # main(in_gpx, out_wav)\n",
    "    try:\n",
    "        in_gpx = gpx_path\n",
    "        out_wav = '/content/gpx.wav'\n",
    "        main(in_gpx, out_wav)\n",
    "    except Exception:\n",
    "        print('Run main(in_gpx, out_wav) manually when using Google Colab.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
