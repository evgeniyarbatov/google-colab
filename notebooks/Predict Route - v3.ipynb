{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install gdown contextily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from geopy.distance import geodesic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "ROUTE_GPX = 'route.gpx'\n",
    "ROUTE_GPX_URL = 'https://drive.google.com/file/d/1-kx84-fNAOuDWSdVEYU_DjP4Om0yHnaD/view?usp=sharing'\n",
    "gdown.download(ROUTE_GPX_URL, ROUTE_GPX, quiet=True, fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_gpx(filepath):\n",
    "    ns = '{http://www.topografix.com/GPX/1/1}'\n",
    "    root = ET.parse(filepath).getroot()\n",
    "\n",
    "    data = {\n",
    "        'lat': [float(pt.get('lat')) for trk in root.findall(f\".//{ns}trk\")\n",
    "                for seg in trk.findall(f\"{ns}trkseg\")\n",
    "                for pt in seg.findall(f\"{ns}trkpt\")],\n",
    "        'lon': [float(pt.get('lon')) for trk in root.findall(f\".//{ns}trk\")\n",
    "                for seg in trk.findall(f\"{ns}trkseg\")\n",
    "                for pt in seg.findall(f\"{ns}trkpt\")]\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "df = parse_gpx(ROUTE_GPX)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucketize_column(series, n_buckets):\n",
    "    quantiles = series.quantile(np.linspace(0, 1, n_buckets+1))\n",
    "    labels = [f'Bucket_{i}' for i in range(1, len(quantiles))]\n",
    "    return (pd.cut(series, bins=quantiles, labels=labels, include_lowest=True), quantiles)\n",
    "\n",
    "df['lat_bucket'], lat_quantiles = bucketize_column(df['lat'], n_buckets=30)\n",
    "df['lon_bucket'], lon_quantiles = bucketize_column(df['lon'], n_buckets=30)\n",
    "\n",
    "lat_encoder, lon_encoder = LabelEncoder(), LabelEncoder()\n",
    "\n",
    "df['lat_encoded'] = lat_encoder.fit_transform(df['lat_bucket'])\n",
    "df['lon_encoded'] = lon_encoder.fit_transform(df['lon_bucket'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df, label, color='blue'):\n",
    "    plt.figure(dpi=300)\n",
    "    plt.scatter(df['lon'], df['lat'], color=color, marker='*', label=label)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    ctx.add_basemap(plt.gca(), crs='EPSG:4326', source=ctx.providers.OpenStreetMap.Mapnik)\n",
    "    plt.legend()\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "    plt.tick_params(axis='both', which='both', bottom=False, top=False, left=False, right=False)\n",
    "    plt.show()\n",
    "\n",
    "plot(df, 'Original Route')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_df = df.groupby(['lat_bucket', 'lon_bucket']).agg({\n",
    "    'lat': 'first',\n",
    "    'lon': 'first'\n",
    "}).reset_index()\n",
    "plot(bins_df, 'Bins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[['lat_encoded', 'lon_encoded']]\n",
    "X = features.to_numpy()\n",
    "y1 = df['lat_encoded']\n",
    "y2 = df['lon_encoded']\n",
    "\n",
    "X_train, X_test, y1_train, y1_test, y2_train, y2_test = train_test_split(X, y1, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "input_layer = Input(shape=(X_train.shape[1],))\n",
    "hidden = Dense(3, activation='relu')(input_layer)\n",
    "\n",
    "lat_output = Dense(len(lat_encoder.classes_), activation='softmax', name='lat_output')(hidden)\n",
    "lon_output = Dense(len(lon_encoder.classes_), activation='softmax', name='lon_output')(hidden)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=[lat_output, lon_output])\n",
    "\n",
    "# Compile the model with separate loss functions for each output\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'lat_output': 'sparse_categorical_crossentropy',\n",
    "                    'lon_output': 'sparse_categorical_crossentropy'},\n",
    "              metrics={'lat_output': 'accuracy', 'lon_output': 'accuracy'})\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    {'lat_output': y1_train, 'lon_output': y2_train},\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[EarlyStopping(patience=10, restore_best_weights=True)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next(\n",
    "    lat,\n",
    "    lon,\n",
    "    lat_quantiles,\n",
    "    lon_quantiles,\n",
    "    lat_encoder,\n",
    "    lon_encoder,\n",
    "    model,\n",
    "    bins_df,\n",
    "):\n",
    "    new_data = pd.DataFrame({\n",
    "        'lat': [lat],\n",
    "        'lon': [lon],\n",
    "    })\n",
    "\n",
    "    lat_labels = [f'Bucket_{i}' for i in range(1, len(lat_quantiles))]\n",
    "    lon_labels = [f'Bucket_{i}' for i in range(1, len(lon_quantiles))]\n",
    "\n",
    "    new_data['lat_bucket'] = pd.cut(new_data['lat'], bins=lat_quantiles, labels=lat_labels, include_lowest=True)\n",
    "    new_data['lon_bucket'] = pd.cut(new_data['lon'], bins=lon_quantiles, labels=lon_labels, include_lowest=True)\n",
    "\n",
    "    new_data['lat_encoded'] = lat_encoder.transform(new_data['lat_bucket'])\n",
    "    new_data['lon_encoded'] = lon_encoder.transform(new_data['lon_bucket'])\n",
    "\n",
    "    X_new = new_data[['lat_encoded', 'lon_encoded']].to_numpy()\n",
    "    predictions = model.predict(X_new)\n",
    "\n",
    "    lat_bucket_predicted = lat_encoder.inverse_transform([np.argmax(predictions[0][0])])[0]\n",
    "    lon_bucket_predicted = lon_encoder.inverse_transform([np.argmax(predictions[1][0])])[0]\n",
    "\n",
    "    bin_df = bins_df[(bins_df['lat_bucket'] == lat_bucket_predicted) & (bins_df['lon_bucket'] == lon_bucket_predicted)]\n",
    "\n",
    "    # print(f\"Input: {lat}, {lon}\")\n",
    "    # print(f\"Predicted: {bin_df.iloc[0]['lat']} / {bin_df.iloc[0]['lon']}\")\n",
    "\n",
    "    return bin_df.iloc[0]['lat'], bin_df.iloc[0]['lon']\n",
    "\n",
    "predict_next(\n",
    "    20.993691,\n",
    "    105.868892,\n",
    "    lat_quantiles,\n",
    "    lon_quantiles,\n",
    "    lat_encoder,\n",
    "    lon_encoder,\n",
    "    model,\n",
    "    bins_df,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    return geodesic((lat1, lon1), (lat2, lon2)).meters\n",
    "\n",
    "def predict_over_route():\n",
    "    predictions = []\n",
    "    cumulative_distance = 0\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        lat, lon = row['lat'], row['lon']\n",
    "\n",
    "        next_lat, next_lon = predict_next(\n",
    "            lat,\n",
    "            lon,\n",
    "            lat_quantiles,\n",
    "            lon_quantiles,\n",
    "            lat_encoder,\n",
    "            lon_encoder,\n",
    "            model,\n",
    "            bins_df,\n",
    "        )\n",
    "        if pd.isna(next_lat) or pd.isna(next_lon):\n",
    "          continue\n",
    "\n",
    "        dist = haversine_distance(lat, lon, next_lat, next_lon)\n",
    "        cumulative_distance += dist\n",
    "\n",
    "        print(f\"{index} | Current: ({lat:.6f}, {lon:.6f}) | \"\n",
    "              f\"Predicted: ({next_lat:.6f}, {next_lon:.6f}) | \"\n",
    "              f\"Distance : {cumulative_distance:.2f} m\")\n",
    "\n",
    "        if index > 500:\n",
    "          break\n",
    "\n",
    "        predictions.append([next_lat, next_lon])\n",
    "\n",
    "    return predictions\n",
    "\n",
    "predicted_path = predict_over_route()\n",
    "\n",
    "predicted_df = pd.DataFrame(predicted_path, columns=['lat', 'lon'])\n",
    "print(predicted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(predicted_df, 'Predicted Route', color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(df.iloc[:500], 'Actual Route')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
