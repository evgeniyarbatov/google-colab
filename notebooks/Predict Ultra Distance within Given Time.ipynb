{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy scikit-learn gpxpy haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import gpxpy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from haversine import haversine, Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your own GPX file in Google Drive\n",
    "GPX_URL = 'https://drive.google.com/file/d/1LXlrNI0e7Jk3YGD7zVfhjZJllGVrBlmy/view?usp=sharing'\n",
    "\n",
    "# How many hours do you have to run\n",
    "CUTOFF_TIME_HOURS = [4, 5, 7, 9, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REFERENCE_RUN_GPX = 'run.gpx'\n",
    "\n",
    "gdown.download(GPX_URL, REFERENCE_RUN_GPX, quiet=True, fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_gpx(filepath):\n",
    "    gpx_file = open(filepath, 'r')\n",
    "    gpx = gpxpy.parse(gpx_file)\n",
    "\n",
    "    data = []\n",
    "    for track in gpx.tracks:\n",
    "        for segment in track.segments:\n",
    "            for point in segment.points:\n",
    "                time, lat, lng = point.time, point.latitude, point.longitude\n",
    "                data.append({\n",
    "                  'time': time,\n",
    "                  'lat': lat,\n",
    "                  'lon': lng,\n",
    "                })\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "df = parse_gpx(REFERENCE_RUN_GPX)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pace(df):\n",
    "  # Convert the 'time' column to datetime\n",
    "  df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "  # Sort the DataFrame by time to ensure consecutive rows are in correct order\n",
    "  df = df.sort_values(by='time')\n",
    "\n",
    "  # Calculate the distance between consecutive points using the haversine formula\n",
    "  df['distance'] = df.apply(lambda row: haversine(\n",
    "                              (row['lat'], row['lon']),\n",
    "                              (df.iloc[row.name - 1]['lat'], df.iloc[row.name - 1]['lon']),\n",
    "                              unit=Unit.KILOMETERS) if row.name > 0 else 0, axis=1)\n",
    "\n",
    "  # Calculate the time difference between consecutive points (in seconds)\n",
    "  df['time_diff'] = df['time'].diff().dt.total_seconds()\n",
    "\n",
    "  # Avoid division by zero by filling NaNs in 'time_diff' with small values\n",
    "  df['time_diff'].fillna(1, inplace=True)\n",
    "\n",
    "  # Calculate pace (in minutes per kilometer)\n",
    "  df['pace'] = (df['time_diff'] / 60) / df['distance']\n",
    "\n",
    "  # Handle NaNs or infinite pace values (e.g., first row)\n",
    "  df['pace'] = df['pace'].replace([float('inf'), -float('inf')], 0).fillna(0)\n",
    "\n",
    "  # Get cumulative distance\n",
    "  df['cumulative_distance'] = df['distance'].cumsum()\n",
    "\n",
    "  df = df.drop(columns=['distance'])\n",
    "  df.rename(columns={'cumulative_distance': 'distance'}, inplace=True)\n",
    "\n",
    "  return df\n",
    "\n",
    "df = get_pace(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['distance', 'pace']].tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict pace for given distance\n",
    "X = df['distance'].values.reshape(-1, 1)\n",
    "y = df['pace']\n",
    "\n",
    "# Split to test and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit linear regression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sense of the error by fitting known distances\n",
    "X_long = np.array([[10], [21], [42], [50], [100], [123], [200], [322]])\n",
    "y_long_pred = model.predict(X_long)\n",
    "\n",
    "times = X_long.flatten() * y_long_pred\n",
    "for distance, time in zip(X_long.flatten(), times):\n",
    "    print(f'{distance} (km): {time / 60.0:.1f} (hours)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cutoff_distance(time_cutoff, model, step=1, max_iterations=10000):\n",
    "    distance = 0\n",
    "    cumulative_time = 0\n",
    "\n",
    "    for _ in range(max_iterations):\n",
    "        # Predict time for the next unit of distance\n",
    "        predicted_time = model.predict([[distance + step]])[0]\n",
    "\n",
    "        # Check if adding this step would exceed the time cutoff\n",
    "        if cumulative_time + predicted_time > time_cutoff * 60:  # Convert time_cutoff to minutes\n",
    "            break\n",
    "\n",
    "        # Add the step to our distance and time\n",
    "        distance += step\n",
    "        cumulative_time += predicted_time\n",
    "\n",
    "    return distance, cumulative_time / 60  # Convert back to hours\n",
    "\n",
    "for cutoff_time in CUTOFF_TIME_HOURS:\n",
    "  max_distance, time_taken = predict_cutoff_distance(cutoff_time, model)\n",
    "  print(f\"{max_distance:.2f} (km): {time_taken:.2f} (hours)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
