{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, Counter\n",
    "import statistics\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Helper: Should we ignore this field name?\n",
    "# ----------------------------------------------------\n",
    "def should_ignore_field(field_name: str) -> bool:\n",
    "    name = field_name.lower()\n",
    "    return (\n",
    "        \"date\" in name\n",
    "        or \"id\" in name\n",
    "        or \"polyline\" in name\n",
    "    )\n",
    "\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Recursive walker — collects all values by field path\n",
    "# ----------------------------------------------------\n",
    "def walk(prefix: str, obj: Any, store):\n",
    "    \"\"\"Recursively walk objects and store all values under their field path.\"\"\"\n",
    "\n",
    "    # Ignore field if its prefix contains disallowed keywords\n",
    "    if should_ignore_field(prefix):\n",
    "        return\n",
    "\n",
    "    if isinstance(obj, dict):\n",
    "        for k, v in obj.items():\n",
    "            full = f\"{prefix}.{k}\" if prefix else k\n",
    "            if should_ignore_field(full):\n",
    "                continue\n",
    "            walk(full, v, store)\n",
    "\n",
    "    elif isinstance(obj, list):\n",
    "        store[prefix].append(len(obj))\n",
    "        for item in obj:\n",
    "            walk(prefix, item, store)\n",
    "\n",
    "    else:\n",
    "        store[prefix].append(obj)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Main analysis and plotting function\n",
    "# ----------------------------------------------------\n",
    "def analyze_activity(json_path):\n",
    "    print(f\"\\nLoading JSON: {json_path}\\n\")\n",
    "\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    activities = [item[\"activity\"] for item in data]\n",
    "\n",
    "    collected = defaultdict(list)\n",
    "\n",
    "    # collect all values\n",
    "    for act in activities:\n",
    "        walk(\"activity\", act, collected)\n",
    "\n",
    "    print(\"Fields detected (after ignoring date/id/polyline):\", len(collected))\n",
    "    print(\"\\n====================================\")\n",
    "    print(\"     DATA ANALYSIS REPORT\")\n",
    "    print(\"====================================\\n\")\n",
    "\n",
    "    numeric_fields = {}\n",
    "    categorical_fields = {}\n",
    "    boolean_fields = {}\n",
    "    null_only_fields = []\n",
    "    mixed_fields = {}\n",
    "\n",
    "    for field, values in collected.items():\n",
    "\n",
    "        # ignore all nulls\n",
    "        non_null = [v for v in values if v is not None]\n",
    "        if len(non_null) == 0:\n",
    "            null_only_fields.append(field)\n",
    "            continue\n",
    "\n",
    "        # remove constant fields and fully unique fields\n",
    "        unique_count = len(set(non_null))\n",
    "        total_count = len(non_null)\n",
    "\n",
    "        if unique_count == 1 or unique_count == total_count:\n",
    "            continue\n",
    "\n",
    "        types = set(type(v) for v in non_null)\n",
    "\n",
    "        if types <= {int, float}:\n",
    "            numeric_fields[field] = non_null\n",
    "\n",
    "        elif types == {str}:\n",
    "            categorical_fields[field] = non_null\n",
    "\n",
    "        elif types == {bool}:\n",
    "            boolean_fields[field] = non_null\n",
    "\n",
    "        else:\n",
    "            mixed_fields[field] = types\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # Numeric distributions\n",
    "    # ----------------------------------------\n",
    "    print(\"NUMERIC FIELDS:\")\n",
    "    print(\"------------------------------------\")\n",
    "\n",
    "    for field, values in numeric_fields.items():\n",
    "        print(f\"\\n• {field}\")\n",
    "        print(f\"  count = {len(values)}\")\n",
    "        print(f\"  unique = {len(set(values))}\")\n",
    "        print(f\"  min   = {min(values)}\")\n",
    "        print(f\"  max   = {max(values)}\")\n",
    "        print(f\"  mean  = {statistics.mean(values):.4f}\")\n",
    "\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.hist(values, bins=20)\n",
    "        plt.title(f\"{field}\")\n",
    "        plt.xlabel(\"Value\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # Categorical distributions\n",
    "    # ----------------------------------------\n",
    "    print(\"\\nCATEGORICAL FIELDS:\")\n",
    "    print(\"------------------------------------\")\n",
    "\n",
    "    for field, values in categorical_fields.items():\n",
    "        counts = Counter(values)\n",
    "\n",
    "        print(f\"\\n• {field}\")\n",
    "        print(f\"  unique categories = {len(counts)}\")\n",
    "\n",
    "        for k, c in counts.items():\n",
    "            print(f\"   {k}: {c}\")\n",
    "\n",
    "        if len(counts) <= 30:\n",
    "            plt.figure(figsize=(6, 4))\n",
    "            plt.bar(list(counts.keys()), list(counts.values()))\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.title(f\"{field}\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # Boolean distributions\n",
    "    # ----------------------------------------\n",
    "    print(\"\\nBOOLEAN FIELDS:\")\n",
    "    print(\"------------------------------------\")\n",
    "\n",
    "    for field, values in boolean_fields.items():\n",
    "        counts = Counter(values)\n",
    "\n",
    "        # ignore if only True or only False\n",
    "        if len(counts) == 1:\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n• {field}\")\n",
    "        print(f\"   True:  {counts.get(True, 0)}\")\n",
    "        print(f\"   False: {counts.get(False, 0)}\")\n",
    "\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.bar([\"False\", \"True\"], [counts.get(False, 0), counts.get(True, 0)])\n",
    "        plt.title(f\"Boolean Distribution:\\n{field}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    print(\"\\n\\n=== ANALYSIS COMPLETE ===\\n\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Run with your path\n",
    "# ----------------------------------------------------\n",
    "analyze_activity(\"/content/strava_activities_filtered.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from typing import Any\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Ignore fields containing these substrings\n",
    "# ----------------------------------------------------\n",
    "def should_ignore_field(field_name: str) -> bool:\n",
    "    name = field_name.lower()\n",
    "    return \"date\" in name or \"id\" in name or \"polyline\" in name\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Recursively gather numeric values by field path\n",
    "# ----------------------------------------------------\n",
    "def walk(prefix: str, obj: Any, store):\n",
    "    if should_ignore_field(prefix):\n",
    "        return\n",
    "\n",
    "    if isinstance(obj, dict):\n",
    "        for k, v in obj.items():\n",
    "            full = f\"{prefix}.{k}\" if prefix else k\n",
    "            if should_ignore_field(full):\n",
    "                continue\n",
    "            walk(full, v, store)\n",
    "\n",
    "    elif isinstance(obj, list):\n",
    "        # Treat list length as a numeric signal\n",
    "        store[prefix].append(len(obj))\n",
    "        for item in obj:\n",
    "            walk(prefix, item, store)\n",
    "\n",
    "    else:\n",
    "        # Handle numeric only; keep bool separate later\n",
    "        if isinstance(obj, (int, float)) and not isinstance(obj, bool):\n",
    "            store[prefix].append(obj)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Build dataframe from collected numeric fields\n",
    "# ----------------------------------------------------\n",
    "def make_dataframe(collected):\n",
    "    filtered = {}\n",
    "    for field, values in collected.items():\n",
    "        non_null = [v for v in values if v is not None]\n",
    "\n",
    "        if len(non_null) < 5:\n",
    "            continue\n",
    "\n",
    "        unique = len(set(non_null))\n",
    "\n",
    "        # Remove constant & all-unique\n",
    "        if unique <= 1 or unique == len(non_null):\n",
    "            continue\n",
    "\n",
    "        filtered[field] = non_null\n",
    "\n",
    "    if not filtered:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # To handle unequal lengths, pad with nan\n",
    "    max_len = max(len(v) for v in filtered.values())\n",
    "    df = pd.DataFrame({\n",
    "        k: v + [np.nan] * (max_len - len(v))\n",
    "        for k, v in filtered.items()\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# CORRELATION + SURPRISINGNESS ANALYSIS\n",
    "# ----------------------------------------------------\n",
    "def analyze_correlations(json_path):\n",
    "    print(f\"\\nLoading: {json_path}\")\n",
    "\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    activities = [item[\"activity\"] for item in data]\n",
    "\n",
    "    collected = defaultdict(list)\n",
    "    for act in activities:\n",
    "        walk(\"activity\", act, collected)\n",
    "\n",
    "    # Build usable dataframe\n",
    "    df = make_dataframe(collected)\n",
    "    if df.empty:\n",
    "        print(\"No numeric data to analyze.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Fields kept for numeric analysis: {len(df.columns)}\")\n",
    "    print(list(df.columns))\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 1. Correlation Heatmap\n",
    "    # ----------------------------------------------------\n",
    "    corr = df.corr(numeric_only=True)\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.imshow(corr, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "    plt.colorbar(label=\"Correlation\")\n",
    "    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
    "    plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 2. Strong Correlation Scatter Plots\n",
    "    # ----------------------------------------------------\n",
    "    threshold = 0.6\n",
    "    strong_pairs = [\n",
    "        (c1, c2, corr.iloc[i, j])\n",
    "        for i, c1 in enumerate(corr.columns)\n",
    "        for j, c2 in enumerate(corr.columns)\n",
    "        if j > i and abs(corr.iloc[i, j]) >= threshold\n",
    "    ]\n",
    "\n",
    "    print(\"\\nStrong correlations (|r| >= 0.6):\")\n",
    "    for a, b, r in strong_pairs:\n",
    "        print(f\"  {a}  vs  {b} : r = {r:.3f}\")\n",
    "        plt.figure(figsize=(5, 4))\n",
    "        plt.scatter(df[a], df[b])\n",
    "        plt.xlabel(a)\n",
    "        plt.ylabel(b)\n",
    "        plt.title(f\"Strong Correlation: r={r:.3f}\\n{a} vs {b}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# RUN\n",
    "# ----------------------------------------------------\n",
    "analyze_correlations(\"/content/strava_activities_filtered.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
