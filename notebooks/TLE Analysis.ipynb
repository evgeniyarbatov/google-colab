{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('/content/tles.parquet')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "  print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "class GNSSTLEExplorer:\n",
    "    \"\"\"Explore GNSS TLE data for interesting patterns and connections\"\"\"\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "        self._preprocess_data()\n",
    "\n",
    "    def _preprocess_data(self):\n",
    "        \"\"\"Preprocess and clean the data\"\"\"\n",
    "        # Convert date columns to datetime\n",
    "        date_cols = ['CREATION_DATE', 'EPOCH', 'LAUNCH_DATE', 'DECAY_DATE']\n",
    "        for col in date_cols:\n",
    "            if col in self.df.columns:\n",
    "                self.df[col] = pd.to_datetime(self.df[col], errors='coerce')\n",
    "\n",
    "        # Convert numeric columns\n",
    "        numeric_cols = ['MEAN_MOTION', 'ECCENTRICITY', 'INCLINATION',\n",
    "                       'RA_OF_ASC_NODE', 'ARG_OF_PERICENTER', 'MEAN_ANOMALY',\n",
    "                       'BSTAR', 'SEMIMAJOR_AXIS', 'PERIOD', 'APOAPSIS',\n",
    "                       'PERIAPSIS', 'REV_AT_EPOCH']\n",
    "\n",
    "        for col in numeric_cols:\n",
    "            if col in self.df.columns:\n",
    "                self.df[col] = pd.to_numeric(self.df[col], errors='coerce')\n",
    "\n",
    "    def summary_statistics(self):\n",
    "        \"\"\"Generate comprehensive summary statistics\"\"\"\n",
    "        print(\"=\"*80)\n",
    "        print(\"GNSS TLE DATA EXPLORATION SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        print(f\"\\nüìä Dataset Shape: {self.df.shape[0]} rows √ó {self.df.shape[1]} columns\")\n",
    "        print(f\"üìÖ Date Range: {self.df['EPOCH'].min()} to {self.df['EPOCH'].max()}\")\n",
    "\n",
    "        # Constellation breakdown\n",
    "        if 'OBJECT_NAME' in self.df.columns:\n",
    "            print(\"\\nüõ∞Ô∏è  GNSS Constellation Breakdown:\")\n",
    "            constellations = self._identify_constellations()\n",
    "            for const, count in constellations.items():\n",
    "                print(f\"   {const}: {count} satellites\")\n",
    "\n",
    "        # Country distribution\n",
    "        if 'COUNTRY_CODE' in self.df.columns:\n",
    "            print(\"\\nüåç Country Distribution:\")\n",
    "            top_countries = self.df['COUNTRY_CODE'].value_counts().head(10)\n",
    "            for country, count in top_countries.items():\n",
    "                print(f\"   {country}: {count} objects\")\n",
    "\n",
    "        # Orbital characteristics\n",
    "        print(\"\\nüî≠ Orbital Characteristics:\")\n",
    "        if 'SEMIMAJOR_AXIS' in self.df.columns:\n",
    "            print(f\"   Semimajor Axis: {self.df['SEMIMAJOR_AXIS'].mean():.2f} km (mean)\")\n",
    "        if 'INCLINATION' in self.df.columns:\n",
    "            print(f\"   Inclination: {self.df['INCLINATION'].mean():.2f}¬∞ (mean)\")\n",
    "        if 'ECCENTRICITY' in self.df.columns:\n",
    "            print(f\"   Eccentricity: {self.df['ECCENTRICITY'].mean():.6f} (mean)\")\n",
    "        if 'PERIOD' in self.df.columns:\n",
    "            print(f\"   Orbital Period: {self.df['PERIOD'].mean():.2f} minutes (mean)\")\n",
    "\n",
    "    def _identify_constellations(self):\n",
    "        \"\"\"Identify GNSS constellations from object names\"\"\"\n",
    "        constellations = {\n",
    "            'GPS': 0, 'GLONASS': 0, 'GALILEO': 0, 'BEIDOU': 0,\n",
    "            'QZSS': 0, 'IRNSS/NavIC': 0, 'SBAS': 0, 'Other': 0\n",
    "        }\n",
    "\n",
    "        for name in self.df['OBJECT_NAME'].dropna():\n",
    "            name_upper = str(name).upper()\n",
    "            if 'GPS' in name_upper or 'NAVSTAR' in name_upper:\n",
    "                constellations['GPS'] += 1\n",
    "            elif 'GLONASS' in name_upper or 'COSMOS' in name_upper:\n",
    "                constellations['GLONASS'] += 1\n",
    "            elif 'GALILEO' in name_upper or 'GSAT' in name_upper:\n",
    "                constellations['GALILEO'] += 1\n",
    "            elif 'BEIDOU' in name_upper or 'BEIDOU' in name_upper:\n",
    "                constellations['BEIDOU'] += 1\n",
    "            elif 'QZSS' in name_upper or 'MICHIBIKI' in name_upper:\n",
    "                constellations['QZSS'] += 1\n",
    "            elif 'IRNSS' in name_upper or 'NAVIC' in name_upper:\n",
    "                constellations['IRNSS/NavIC'] += 1\n",
    "            elif any(x in name_upper for x in ['SBAS', 'WAAS', 'EGNOS', 'GAGAN', 'MSAS']):\n",
    "                constellations['SBAS'] += 1\n",
    "            else:\n",
    "                constellations['Other'] += 1\n",
    "\n",
    "        return {k: v for k, v in constellations.items() if v > 0}\n",
    "\n",
    "    def find_orbital_clusters(self):\n",
    "        \"\"\"Find satellites with similar orbital parameters\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üîç ORBITAL CLUSTERING ANALYSIS\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        required_cols = ['SEMIMAJOR_AXIS', 'INCLINATION', 'ECCENTRICITY']\n",
    "        if not all(col in self.df.columns for col in required_cols):\n",
    "            print(\"Missing required orbital parameters\")\n",
    "            return\n",
    "\n",
    "        # Group by similar orbital parameters\n",
    "        df_orb = self.df.dropna(subset=required_cols)\n",
    "\n",
    "        # Define tolerance for clustering\n",
    "        sma_bins = pd.cut(df_orb['SEMIMAJOR_AXIS'], bins=20)\n",
    "        inc_bins = pd.cut(df_orb['INCLINATION'], bins=15)\n",
    "\n",
    "        clusters = df_orb.groupby([sma_bins, inc_bins]).size()\n",
    "        clusters = clusters[clusters > 1].sort_values(ascending=False)\n",
    "\n",
    "        print(f\"\\nüìç Found {len(clusters)} orbital clusters with 2+ satellites\")\n",
    "        print(\"\\nTop 5 clusters:\")\n",
    "        for idx, (params, count) in enumerate(clusters.head().items(), 1):\n",
    "            sma_range, inc_range = params\n",
    "            print(f\"\\n   Cluster {idx}: {count} satellites\")\n",
    "            print(f\"      Semimajor Axis: {sma_range}\")\n",
    "            print(f\"      Inclination: {inc_range}\")\n",
    "\n",
    "    def analyze_launch_trends(self):\n",
    "        \"\"\"Analyze launch dates and trends\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üöÄ LAUNCH TRENDS ANALYSIS\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        if 'LAUNCH_DATE' not in self.df.columns:\n",
    "            print(\"Launch date information not available\")\n",
    "            return\n",
    "\n",
    "        df_launch = self.df.dropna(subset=['LAUNCH_DATE'])\n",
    "\n",
    "        # Launches by year\n",
    "        df_launch['LAUNCH_YEAR'] = df_launch['LAUNCH_DATE'].dt.year\n",
    "        launches_by_year = df_launch['LAUNCH_YEAR'].value_counts().sort_index()\n",
    "\n",
    "        print(f\"\\nüìà Launch activity from {launches_by_year.index.min()} to {launches_by_year.index.max()}\")\n",
    "        print(f\"   Total launches: {len(df_launch)}\")\n",
    "        print(f\"   Peak year: {launches_by_year.idxmax()} ({launches_by_year.max()} launches)\")\n",
    "        print(f\"   Average per year: {launches_by_year.mean():.1f}\")\n",
    "\n",
    "        # Recent launches (last 5 years)\n",
    "        recent = df_launch[df_launch['LAUNCH_YEAR'] >= launches_by_year.index.max() - 4]\n",
    "        print(f\"\\nüìÖ Recent launches (last 5 years): {len(recent)}\")\n",
    "\n",
    "    def find_unusual_orbits(self):\n",
    "        \"\"\"Identify satellites with unusual orbital characteristics\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üåü UNUSUAL ORBIT DETECTION\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        # High eccentricity orbits\n",
    "        if 'ECCENTRICITY' in self.df.columns:\n",
    "            high_ecc = self.df[self.df['ECCENTRICITY'] > 0.01]\n",
    "            if len(high_ecc) > 0:\n",
    "                print(f\"\\n‚≠ï High Eccentricity Orbits (e > 0.01): {len(high_ecc)} satellites\")\n",
    "                for _, row in high_ecc.nlargest(3, 'ECCENTRICITY').iterrows():\n",
    "                    print(f\"   - {row['OBJECT_NAME']}: e = {row['ECCENTRICITY']:.6f}\")\n",
    "\n",
    "        # Unusual inclinations\n",
    "        if 'INCLINATION' in self.df.columns:\n",
    "            mean_inc = self.df['INCLINATION'].mean()\n",
    "            std_inc = self.df['INCLINATION'].std()\n",
    "            unusual_inc = self.df[abs(self.df['INCLINATION'] - mean_inc) > 2 * std_inc]\n",
    "\n",
    "            if len(unusual_inc) > 0:\n",
    "                print(f\"\\nüìê Unusual Inclinations (>2œÉ from mean): {len(unusual_inc)} satellites\")\n",
    "                for _, row in unusual_inc.head(3).iterrows():\n",
    "                    print(f\"   - {row['OBJECT_NAME']}: {row['INCLINATION']:.2f}¬∞\")\n",
    "\n",
    "        # Very high or low altitudes\n",
    "        if 'SEMIMAJOR_AXIS' in self.df.columns:\n",
    "            mean_sma = self.df['SEMIMAJOR_AXIS'].mean()\n",
    "            high_alt = self.df[self.df['SEMIMAJOR_AXIS'] > mean_sma * 1.5]\n",
    "\n",
    "            if len(high_alt) > 0:\n",
    "                print(f\"\\nüõ∏ High Altitude Orbits (>1.5√ó mean): {len(high_alt)} satellites\")\n",
    "                for _, row in high_alt.nlargest(3, 'SEMIMAJOR_AXIS').iterrows():\n",
    "                    print(f\"   - {row['OBJECT_NAME']}: {row['SEMIMAJOR_AXIS']:.2f} km\")\n",
    "\n",
    "    def correlation_analysis(self):\n",
    "        \"\"\"Analyze correlations between orbital parameters\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üìä CORRELATION ANALYSIS\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        orbital_params = ['MEAN_MOTION', 'ECCENTRICITY', 'INCLINATION',\n",
    "                         'SEMIMAJOR_AXIS', 'PERIOD', 'APOAPSIS', 'PERIAPSIS']\n",
    "\n",
    "        available_params = [p for p in orbital_params if p in self.df.columns]\n",
    "\n",
    "        if len(available_params) < 2:\n",
    "            print(\"Insufficient orbital parameters for correlation analysis\")\n",
    "            return\n",
    "\n",
    "        corr_matrix = self.df[available_params].corr()\n",
    "\n",
    "        print(\"\\nüîó Strong correlations (|r| > 0.7):\")\n",
    "        for i in range(len(corr_matrix.columns)):\n",
    "            for j in range(i+1, len(corr_matrix.columns)):\n",
    "                corr_val = corr_matrix.iloc[i, j]\n",
    "                if abs(corr_val) > 0.7:\n",
    "                    param1 = corr_matrix.columns[i]\n",
    "                    param2 = corr_matrix.columns[j]\n",
    "                    print(f\"   {param1} ‚Üî {param2}: r = {corr_val:.3f}\")\n",
    "\n",
    "    def temporal_patterns(self):\n",
    "        \"\"\"Analyze temporal patterns in the data\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"‚è∞ TEMPORAL PATTERNS\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        if 'EPOCH' not in self.df.columns:\n",
    "            print(\"Epoch information not available\")\n",
    "            return\n",
    "\n",
    "        df_time = self.df.dropna(subset=['EPOCH'])\n",
    "\n",
    "        # Time span coverage\n",
    "        time_span = (df_time['EPOCH'].max() - df_time['EPOCH'].min()).days\n",
    "        print(f\"\\nüìÖ Epoch time span: {time_span} days ({time_span/365.25:.1f} years)\")\n",
    "\n",
    "        # Data freshness\n",
    "        if 'CREATION_DATE' in self.df.columns:\n",
    "            df_created = self.df.dropna(subset=['CREATION_DATE'])\n",
    "            most_recent = df_created['CREATION_DATE'].max()\n",
    "            print(f\"üìù Most recent TLE creation: {most_recent}\")\n",
    "\n",
    "            # Age distribution\n",
    "            df_created['AGE_DAYS'] = (pd.Timestamp.now() - df_created['CREATION_DATE']).dt.days\n",
    "            print(f\"   Average TLE age: {df_created['AGE_DAYS'].mean():.1f} days\")\n",
    "\n",
    "    def object_type_analysis(self):\n",
    "        \"\"\"Analyze object types and classifications\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üè∑Ô∏è  OBJECT CLASSIFICATION\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        if 'OBJECT_TYPE' in self.df.columns:\n",
    "            print(\"\\nüìã Object Types:\")\n",
    "            obj_types = self.df['OBJECT_TYPE'].value_counts()\n",
    "            for obj_type, count in obj_types.items():\n",
    "                print(f\"   {obj_type}: {count}\")\n",
    "\n",
    "        if 'CLASSIFICATION_TYPE' in self.df.columns:\n",
    "            print(\"\\nüîê Classification Types:\")\n",
    "            class_types = self.df['CLASSIFICATION_TYPE'].value_counts()\n",
    "            for class_type, count in class_types.items():\n",
    "                print(f\"   {class_type}: {count}\")\n",
    "\n",
    "        if 'RCS_SIZE' in self.df.columns:\n",
    "            print(\"\\nüìè RCS Size Distribution:\")\n",
    "            rcs_dist = self.df['RCS_SIZE'].value_counts()\n",
    "            for rcs, count in rcs_dist.items():\n",
    "                print(f\"   {rcs}: {count}\")\n",
    "\n",
    "    def generate_visualizations(self):\n",
    "        \"\"\"Generate comprehensive visualizations\"\"\"\n",
    "        fig = plt.figure(figsize=(16, 12))\n",
    "\n",
    "        # 1. Inclination vs Semimajor Axis scatter\n",
    "        ax1 = plt.subplot(2, 3, 1)\n",
    "        if 'INCLINATION' in self.df.columns and 'SEMIMAJOR_AXIS' in self.df.columns:\n",
    "            plt.scatter(self.df['SEMIMAJOR_AXIS'], self.df['INCLINATION'],\n",
    "                       alpha=0.6, s=50)\n",
    "            plt.xlabel('Semimajor Axis (km)')\n",
    "            plt.ylabel('Inclination (degrees)')\n",
    "            plt.title('Orbital Configuration')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "\n",
    "        # 2. Eccentricity distribution\n",
    "        ax2 = plt.subplot(2, 3, 2)\n",
    "        if 'ECCENTRICITY' in self.df.columns:\n",
    "            self.df['ECCENTRICITY'].hist(bins=30, edgecolor='black')\n",
    "            plt.xlabel('Eccentricity')\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.title('Eccentricity Distribution')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "\n",
    "        # 3. Launch timeline\n",
    "        ax3 = plt.subplot(2, 3, 3)\n",
    "        if 'LAUNCH_DATE' in self.df.columns:\n",
    "            df_launch = self.df.dropna(subset=['LAUNCH_DATE'])\n",
    "            df_launch['LAUNCH_YEAR'] = df_launch['LAUNCH_DATE'].dt.year\n",
    "            launches = df_launch['LAUNCH_YEAR'].value_counts().sort_index()\n",
    "            launches.plot(kind='bar')\n",
    "            plt.xlabel('Year')\n",
    "            plt.ylabel('Number of Launches')\n",
    "            plt.title('Launch Timeline')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.grid(True, alpha=0.3)\n",
    "\n",
    "        # 4. Period vs Altitude\n",
    "        ax4 = plt.subplot(2, 3, 4)\n",
    "        if 'PERIOD' in self.df.columns and 'SEMIMAJOR_AXIS' in self.df.columns:\n",
    "            plt.scatter(self.df['SEMIMAJOR_AXIS'], self.df['PERIOD'],\n",
    "                       alpha=0.6, s=50, c=self.df['INCLINATION'], cmap='viridis')\n",
    "            plt.xlabel('Semimajor Axis (km)')\n",
    "            plt.ylabel('Period (minutes)')\n",
    "            plt.title('Period vs Altitude (colored by inclination)')\n",
    "            plt.colorbar(label='Inclination (¬∞)')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "\n",
    "        # 5. Country distribution\n",
    "        ax5 = plt.subplot(2, 3, 5)\n",
    "        if 'COUNTRY_CODE' in self.df.columns:\n",
    "            top_countries = self.df['COUNTRY_CODE'].value_counts().head(10)\n",
    "            top_countries.plot(kind='barh')\n",
    "            plt.xlabel('Number of Objects')\n",
    "            plt.ylabel('Country Code')\n",
    "            plt.title('Top 10 Countries')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "\n",
    "        # 6. Apoapsis vs Periapsis\n",
    "        ax6 = plt.subplot(2, 3, 6)\n",
    "        if 'APOAPSIS' in self.df.columns and 'PERIAPSIS' in self.df.columns:\n",
    "            plt.scatter(self.df['PERIAPSIS'], self.df['APOAPSIS'],\n",
    "                       alpha=0.6, s=50)\n",
    "            plt.xlabel('Periapsis (km)')\n",
    "            plt.ylabel('Apoapsis (km)')\n",
    "            plt.title('Orbit Shape (Apoapsis vs Periapsis)')\n",
    "            plt.plot([self.df['PERIAPSIS'].min(), self.df['APOAPSIS'].max()],\n",
    "                    [self.df['PERIAPSIS'].min(), self.df['APOAPSIS'].max()],\n",
    "                    'r--', alpha=0.5, label='Circular orbit line')\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('gnss_tle_exploration.png', dpi=300, bbox_inches='tight')\n",
    "        print(\"\\nüìä Visualizations saved as 'gnss_tle_exploration.png'\")\n",
    "        plt.show()\n",
    "\n",
    "    def full_exploration(self):\n",
    "        \"\"\"Run complete exploration suite\"\"\"\n",
    "        self.summary_statistics()\n",
    "        self.find_orbital_clusters()\n",
    "        self.analyze_launch_trends()\n",
    "        self.find_unusual_orbits()\n",
    "        self.correlation_analysis()\n",
    "        self.temporal_patterns()\n",
    "        self.object_type_analysis()\n",
    "\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"‚úÖ EXPLORATION COMPLETE\")\n",
    "        print(\"=\"*80)\n",
    "        print(\"\\nGenerating visualizations...\")\n",
    "        self.generate_visualizations()\n",
    "\n",
    "df = pd.read_parquet('/content/tles.parquet')\n",
    "explorer = GNSSTLEExplorer(df)\n",
    "explorer.full_exploration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
